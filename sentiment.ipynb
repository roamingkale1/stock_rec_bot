{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53facd1-8dbb-4841-bc01-1362f76de0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /Users/x/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "Analyzing headlines: 100%|██████████| 1460433/1460433 [01:24<00:00, 17367.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment distribution (%):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral     50.19\n",
       "positive    30.73\n",
       "negative    19.08\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POSITIVE EXAMPLES:\n",
      " - Cumbria - Entertainment - Tom Hingley \"Un-guarded\" - BBC\n",
      " - Gift idea : pre-packaged, bioengineered pets - Core77\n",
      " - Another day, another exotic supercar: the Edran Enigma - Motor Authority\n",
      " - Survivor: Cook Islands - Box Office Prophets\n",
      " - Healdsburg restaurant has a new chef but its claim to fame remains the same - The Press Democrat\n",
      "\n",
      "NEUTRAL EXAMPLES:\n",
      " - Interview: Margaret Morrison, Founder And Director of Cybercandy - Londonist\n",
      " - Leicester - Features - Return of the Blaby Tomatoes - BBC\n",
      " - Paul Smith At Borough Market - Londonist\n",
      " - Marcie Shatula Interview- Mmm Blueberries - Pinkbike\n",
      " - Interstate '82 - Eurogamer\n",
      "\n",
      "NEGATIVE EXAMPLES:\n",
      " - Computer feels your rage - Australian Broadcasting Corporation\n",
      " - Mmm…. Teaser - empireonline.com\n",
      " - \"Flushed Away\": DreamWorks' $100 Million Dump - TMZ\n",
      " - Taking Violence to a New, Technological Absurdity (Published 2007) - The New York Times\n",
      " - Mavrodi Convicted of Fraud in MMM Trial - The Moscow Times\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm   # ✅ text-only progress bar\n",
    "from IPython.display import display\n",
    "\n",
    "# ---- Setup ----\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # just in case, avoid warnings\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# ---- Load data ----\n",
    "df = pd.read_csv(\"sp500_headlines.csv\")\n",
    "\n",
    "# ---- Init VADER ----\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "# ---- Apply with text-only progress ----\n",
    "tqdm.pandas(desc=\"Analyzing headlines\")  # adds progress_apply to pandas\n",
    "df[\"sentiment\"] = df[\"title\"].progress_apply(get_sentiment)\n",
    "\n",
    "# ---- Distribution ----\n",
    "distribution = df[\"sentiment\"].value_counts(normalize=True) * 100\n",
    "print(\"\\nSentiment distribution (%):\")\n",
    "display(distribution.round(2))  # ✅ prettier in Jupyter\n",
    "\n",
    "# ---- Show 5 examples per class ----\n",
    "for sentiment in [\"positive\", \"neutral\", \"negative\"]:\n",
    "    print(f\"\\n{sentiment.upper()} EXAMPLES:\")\n",
    "    ex = df[df[\"sentiment\"] == sentiment][\"title\"].head(5)\n",
    "    if ex.empty:\n",
    "        print(\" (none found)\")\n",
    "    else:\n",
    "        for t in ex:\n",
    "            print(\" -\", t)\n",
    "\n",
    "# ---- Optional: Save results ----\n",
    "df.to_csv(\"sp500_headlines_with_vader.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301b33ca-097a-44ef-b6ec-90d76eb0fa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing headlines: 100%|##########| 11410/11410 [2:21:28<00:00,  1.34it/s]    \n",
      "\n",
      "Sentiment distribution (%):\n",
      "positive    46.28\n",
      "neutral      2.06\n",
      "negative    51.67\n",
      "\n",
      "POSITIVE EXAMPLES:\n",
      " - Interview: Margaret Morrison, Founder And Director of Cybercandy - Londonist\n",
      " - Paul Smith At Borough Market - Londonist\n",
      " - Mmm…. Teaser - empireonline.com\n",
      " - Another day, another exotic supercar: the Edran Enigma - Motor Authority\n",
      " - Interstate '82 - Eurogamer\n",
      "\n",
      "NEUTRAL EXAMPLES:\n",
      " - Two and a Half Men Recap: \"Mmm, fish. Yum.\" - TV Fanatic\n",
      " - Maison Martin Margiela 20 - Dazed\n",
      " - Miley Cyrus: Pink Polka Dot Bikini! - Just Jared Jr\n",
      " - It's Food Truck Heaven Every Wednesday Night in Cerritos - Patch\n",
      " - EXCLUSIVE! Chris Evans Naked! We Repeat: CHRIS EVANS NAKED! - Perez Hilton\n",
      "\n",
      "NEGATIVE EXAMPLES:\n",
      " - Cumbria - Entertainment - Tom Hingley \"Un-guarded\" - BBC\n",
      " - Leicester - Features - Return of the Blaby Tomatoes - BBC\n",
      " - Computer feels your rage - Australian Broadcasting Corporation\n",
      " - Marcie Shatula Interview- Mmm Blueberries - Pinkbike\n",
      " - Gift idea : pre-packaged, bioengineered pets - Core77\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from tqdm import tqdm  # ✅ text-only progress bar (no widgets)\n",
    "\n",
    "# Keep notebook output tidy\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# ---- Speed/Device setup ----\n",
    "def pick_device_for_pipeline():\n",
    "    \"\"\"\n",
    "    Returns a device handle suitable for transformers.pipeline:\n",
    "      - torch.device('mps') on Apple Silicon if available\n",
    "      - 0 for first CUDA GPU\n",
    "      - -1 for CPU\n",
    "    \"\"\"\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "device = pick_device_for_pipeline()\n",
    "\n",
    "# ---- Load data ----\n",
    "df = pd.read_csv(\"sp500_headlines.csv\")\n",
    "\n",
    "# ---- Model ----\n",
    "MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    device=device,  # uses MPS/CUDA if available, else CPU\n",
    ")\n",
    "\n",
    "# ---- Run inference with text-only progress ----\n",
    "texts = df[\"title\"].astype(str).tolist()\n",
    "batch_size = 128\n",
    "results = []\n",
    "\n",
    "# Plain-text tqdm (no widgets), good in Jupyter/terminal\n",
    "for i in tqdm(\n",
    "    range(0, len(texts), batch_size),\n",
    "    desc=\"Processing headlines\",\n",
    "    ascii=True,\n",
    "    dynamic_ncols=True,\n",
    "    leave=True,\n",
    "    file=sys.stdout,   # ensure text bar prints to cell output\n",
    "):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    preds = nlp(\n",
    "        batch,\n",
    "        batch_size=batch_size,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=48,  # headlines are short; keeps it fast\n",
    "    )\n",
    "    results.extend(preds)\n",
    "\n",
    "# ---- Map to 3 classes (add neutral band around 0.5) ----\n",
    "def map_to_trinary(label, score, neutral_band=0.06):\n",
    "    if abs(score - 0.5) <= neutral_band:\n",
    "        return \"neutral\"\n",
    "    return \"positive\" if label.upper() == \"POSITIVE\" else \"negative\"\n",
    "\n",
    "df[\"sentiment\"] = [map_to_trinary(p[\"label\"], p[\"score\"]) for p in results]\n",
    "\n",
    "# ---- Distribution ----\n",
    "dist = (df[\"sentiment\"].value_counts(normalize=True) * 100).reindex(\n",
    "    [\"positive\", \"neutral\", \"negative\"]\n",
    ").fillna(0).round(2)\n",
    "print(\"\\nSentiment distribution (%):\")\n",
    "print(dist.to_string())\n",
    "\n",
    "# ---- Examples ----\n",
    "for s in [\"positive\", \"neutral\", \"negative\"]:\n",
    "    print(f\"\\n{s.upper()} EXAMPLES:\")\n",
    "    ex = df.loc[df[\"sentiment\"] == s, \"title\"].head(5)\n",
    "    if ex.empty:\n",
    "        print(\" (none found)\")\n",
    "    else:\n",
    "        for t in ex:\n",
    "            print(\" -\", t)\n",
    "\n",
    "# ---- Optional: save results ----\n",
    "df.to_csv(\"headlines_with_sentiment_DistilBERT.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedc7c39-243e-41ed-b5c2-09e3727cc767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Device set to use mps\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring headlines: 1460433/1460433 (100.0%)    83.2 it/s\n",
      "\n",
      "Sentiment distribution (%):\n",
      "positive    22.38\n",
      "neutral     63.80\n",
      "negative    13.82\n",
      "\n",
      "POSITIVE EXAMPLES:\n",
      " - Gift idea : pre-packaged, bioengineered pets - Core77\n",
      " - Another day, another exotic supercar: the Edran Enigma - Motor Authority\n",
      " - Lathrop's 'CHAKA' has zest for life and marinades - The Stockton Record\n",
      " - MMC Welcomes 14 New Faculty Members • News & Events - Marymount Manhattan College\n",
      " - Mmm, mobile: ‘Simpsons’ goes cellular - NBC News\n",
      "\n",
      "NEUTRAL EXAMPLES:\n",
      " - Cumbria - Entertainment - Tom Hingley \"Un-guarded\" - BBC\n",
      " - Interview: Margaret Morrison, Founder And Director of Cybercandy - Londonist\n",
      " - Leicester - Features - Return of the Blaby Tomatoes - BBC\n",
      " - Paul Smith At Borough Market - Londonist\n",
      " - Computer feels your rage - Australian Broadcasting Corporation\n",
      "\n",
      "NEGATIVE EXAMPLES:\n",
      " - \"Flushed Away\": DreamWorks' $100 Million Dump - TMZ\n",
      " - Mmm, sweaty! Women aroused by male scent - NBC News\n",
      " - Taking Violence to a New, Technological Absurdity (Published 2007) - The New York Times\n",
      " - Mavrodi Convicted of Fraud in MMM Trial - The Moscow Times\n",
      " - ''Simpsons Movie'' shatters records - Entertainment Weekly\n",
      "\n",
      "Saved results to sp500_headlines_with_bertweet_calibrated.csv\n"
     ]
    }
   ],
   "source": [
    "# BERTweet 3-class sentiment with calibrated neutral (no widgets)\n",
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# ---- Settings ----\n",
    "CSV_PATH   = \"sp500_headlines.csv\"\n",
    "MODEL_NAME = \"finiteautomata/bertweet-base-sentiment-analysis\"  # 3-class\n",
    "MAX_ROWS   = None     # e.g., 1000\n",
    "BATCH_SIZE = 128\n",
    "MAX_LEN    = 48\n",
    "PRINT_EVERY= 1\n",
    "\n",
    "# --- Neutral calibration (tune these) ---\n",
    "NEU_MIN    = 0.78    # was 0.70\n",
    "NEU_MARGIN = 0.25    # was 0.20\n",
    "SIDE_MIN   = 0.45    # was 0.40\n",
    "ALPHA      = 0.60    # was 0.50\n",
    "VADER_DELTA = 0.08   # was 0.06\n",
    "\n",
    "# Tie-breaker\n",
    "USE_VADER_TIEBREAKER = True\n",
    "\n",
    "# Tidy logs\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "def pick_device_for_pipeline():\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "device = pick_device_for_pipeline()\n",
    "\n",
    "# --- Load data ---\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "if MAX_ROWS is not None:\n",
    "    df = df.head(MAX_ROWS)\n",
    "texts = df[\"title\"].astype(str).tolist()\n",
    "total = len(texts)\n",
    "\n",
    "# --- Load model (force safetensors to avoid torch>=2.6 requirement) ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, use_safetensors=True)\n",
    "\n",
    "# Optional CPU speed-up\n",
    "if device == -1:\n",
    "    model.eval()\n",
    "    model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, framework=\"pt\", device=device)\n",
    "\n",
    "# Optional VADER tie-breaker\n",
    "if USE_VADER_TIEBREAKER:\n",
    "    import nltk\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    nltk.download(\"vader_lexicon\", quiet=True)\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# --- Helpers ---\n",
    "def print_progress(done, total, start_time):\n",
    "    pct = (done / total * 100) if total else 100.0\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = done / elapsed if elapsed > 0 else 0\n",
    "    sys.stdout.write(f\"\\rScoring headlines: {done}/{total} ({pct:5.1f}%)  {rate:6.1f} it/s\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def to_prob_dict(items):\n",
    "    # items: [{'label': 'NEG/NEU/POS' or 'LABEL_i', 'score': float}, ...]\n",
    "    mapping = {\n",
    "        \"LABEL_0\":\"negative\",\"NEGATIVE\":\"negative\",\"NEG\":\"negative\",\n",
    "        \"LABEL_1\":\"neutral\",\"NEUTRAL\":\"neutral\",\"NEU\":\"neutral\",\n",
    "        \"LABEL_2\":\"positive\",\"POSITIVE\":\"positive\",\"POS\":\"positive\",\n",
    "    }\n",
    "    out = {\"positive\":0.0,\"neutral\":0.0,\"negative\":0.0}\n",
    "    for d in items:\n",
    "        out[mapping.get(d[\"label\"].upper(), d[\"label\"].lower())] = float(d[\"score\"])\n",
    "    return out\n",
    "\n",
    "def decide_label(p, text=None):\n",
    "    p_pos, p_neu, p_neg = p[\"positive\"], p[\"neutral\"], p[\"negative\"]\n",
    "    best_non_neu = max(p_pos, p_neg)\n",
    "\n",
    "    # 1) Strict neutral gate\n",
    "    if (p_neu >= NEU_MIN) and ((p_neu - best_non_neu) >= NEU_MARGIN):\n",
    "        return \"neutral\"\n",
    "\n",
    "    # 2) If a side has decent probability, prefer it unless neutral clearly dominates\n",
    "    if max(p_pos, p_neg) >= SIDE_MIN:\n",
    "        chosen = \"positive\" if p_pos >= p_neg else \"negative\"\n",
    "        return chosen\n",
    "\n",
    "    # 3) Apply neutral penalty and pick side by adjusted scores\n",
    "    s_pos = p_pos - ALPHA * p_neu\n",
    "    s_neg = p_neg - ALPHA * p_neu\n",
    "    if abs(s_pos - s_neg) < 0.06 and USE_VADER_TIEBREAKER and text is not None:\n",
    "        s = vader.polarity_scores(text)[\"compound\"]\n",
    "        if s >= VADER_DELTA:  return \"positive\"\n",
    "        if s <= -VADER_DELTA: return \"negative\"\n",
    "    return \"positive\" if s_pos >= s_neg else \"negative\"\n",
    "\n",
    "# --- Inference (text-only progress) ---\n",
    "results = []\n",
    "start = time.time()\n",
    "done = 0\n",
    "\n",
    "for i in range(0, total, BATCH_SIZE):\n",
    "    batch = texts[i:i+BATCH_SIZE]\n",
    "    scored = nlp(\n",
    "        batch,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_all_scores=True,\n",
    "    )\n",
    "    for item, text in zip(scored, batch):\n",
    "        p = to_prob_dict(item)\n",
    "        results.append(decide_label(p, text))\n",
    "    done += len(batch)\n",
    "    if ((i // BATCH_SIZE) % PRINT_EVERY) == 0:\n",
    "        print_progress(done, total, start)\n",
    "\n",
    "sys.stdout.write(\"\\n\")\n",
    "\n",
    "# --- Results ---\n",
    "df[\"sentiment\"] = results\n",
    "\n",
    "dist = (df[\"sentiment\"].value_counts(normalize=True) * 100).reindex(\n",
    "    [\"positive\",\"neutral\",\"negative\"]\n",
    ").fillna(0).round(2)\n",
    "\n",
    "print(\"\\nSentiment distribution (%):\")\n",
    "print(dist.to_string())\n",
    "\n",
    "for s in [\"positive\",\"neutral\",\"negative\"]:\n",
    "    print(f\"\\n{s.upper()} EXAMPLES:\")\n",
    "    ex = df.loc[df[\"sentiment\"] == s, \"title\"].head(5)\n",
    "    if ex.empty:\n",
    "        print(\" (none found)\")\n",
    "    else:\n",
    "        for t in ex:\n",
    "            print(\" -\", t)\n",
    "\n",
    "out_path = \"sp500_headlines_with_bertweet_calibrated.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved results to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99023ba3-5d65-4447-bd00-f53eee77eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing headlines:  19%|#8        | 2134/11410 [36:02<2:36:41,  1.01s/it] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from tqdm import tqdm  # text-only progress bar\n",
    "\n",
    "# Keep notebook output tidy\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "# ---- Device pick (MPS > CUDA > CPU) ----\n",
    "def pick_device_for_pipeline():\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "device = pick_device_for_pipeline()\n",
    "\n",
    "# ---- Config ----\n",
    "CSV_PATH = \"sp500_headlines.csv\"\n",
    "PRIMARY_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"   # 3-class\n",
    "FALLBACK_MODEL = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"     # 3-class, safetensors present\n",
    "\n",
    "# ---- Load data ----\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "texts = df[\"title\"].astype(str).tolist()\n",
    "\n",
    "# ---- Load model (force safetensors to avoid torch.load restriction) ----\n",
    "def load_model_and_tokenizer(model_name: str):\n",
    "    tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        use_safetensors=True,   # <-- critical: bypasses torch.load path\n",
    "    )\n",
    "    return tok, mdl\n",
    "\n",
    "try:\n",
    "    tokenizer, model = load_model_and_tokenizer(PRIMARY_MODEL)\n",
    "except Exception as e:\n",
    "    print(f\"[INFO] Could not load '{PRIMARY_MODEL}' with safetensors: {e}\")\n",
    "    print(f\"[INFO] Falling back to '{FALLBACK_MODEL}' ...\")\n",
    "    tokenizer, model = load_model_and_tokenizer(FALLBACK_MODEL)\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    device=device,  # MPS/CUDA if available, else CPU\n",
    ")\n",
    "\n",
    "# ---- Inference with text-only progress ----\n",
    "batch_size = 128\n",
    "results = []\n",
    "for i in tqdm(\n",
    "    range(0, len(texts), batch_size),\n",
    "    desc=\"Processing headlines\",\n",
    "    ascii=True,\n",
    "    dynamic_ncols=True,\n",
    "    leave=True,\n",
    "    file=sys.stdout,   # ensure progress prints in cell/terminal\n",
    "):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    preds = nlp(\n",
    "        batch,\n",
    "        batch_size=batch_size,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=48,  # headlines are short; keeps it fast\n",
    "    )\n",
    "    results.extend(preds)\n",
    "\n",
    "# ---- Map labels to 'negative'/'neutral'/'positive' ----\n",
    "# CardiffNLP models return LABEL_0/1/2 with the following mapping:\n",
    "#   LABEL_0 = negative, LABEL_1 = neutral, LABEL_2 = positive\n",
    "label_map = {\"LABEL_0\": \"negative\", \"LABEL_1\": \"neutral\", \"LABEL_2\": \"positive\"}\n",
    "df[\"sentiment\"] = [label_map.get(r.get(\"label\", \"\"), r.get(\"label\", \"\")).lower() for r in results]\n",
    "\n",
    "# ---- Distribution ----\n",
    "dist = (df[\"sentiment\"].value_counts(normalize=True) * 100).reindex(\n",
    "    [\"positive\", \"neutral\", \"negative\"]\n",
    ").fillna(0).round(2)\n",
    "\n",
    "print(\"\\nSentiment distribution (%):\")\n",
    "print(dist.to_string())\n",
    "\n",
    "# ---- Show 5 examples per class ----\n",
    "for s in [\"positive\", \"neutral\", \"negative\"]:\n",
    "    print(f\"\\n{s.upper()} EXAMPLES:\")\n",
    "    ex = df.loc[df[\"sentiment\"] == s, \"title\"].head(5)\n",
    "    if ex.empty:\n",
    "        print(\" (none found)\")\n",
    "    else:\n",
    "        for t in ex:\n",
    "            print(\" -\", t)\n",
    "\n",
    "# ---- Save results ----\n",
    "out_path = \"sp500_headlines_with_cardiffnlp.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved results to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8aae3b-2ca1-4597-a4dd-cfe5ff77d3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362b384-6dcc-4ad6-acaf-777f4e394e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d18e4b4-7a6d-4b6c-83a1-cf32db203200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f801fd-50be-42b0-b180-f6fbf76f07c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ac6da-fb96-496a-83f9-d26423278e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "# from tqdm import tqdm  # text-only progress bar\n",
    "\n",
    "# # --- Clean output in notebooks/terminal ---\n",
    "# os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "# # === Choose your 3-class model (pick one) ===\n",
    "# # A) CardiffNLP RoBERTa (3-class, general short text)\n",
    "# MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "# # B) BERTweet (often a bit “spicier” than RoBERTa on headlines)\n",
    "# # MODEL_NAME = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "# # C) FinBERT-tone (finance; 3-class; usually faster than Prosus finbert)\n",
    "# # MODEL_NAME = \"yiyanghkust/finbert-tone\"\n",
    "\n",
    "# CSV_PATH = \"sp500_headlines.csv\"\n",
    "\n",
    "# # --- Device selection for the pipeline (MPS > CUDA > CPU) ---\n",
    "# def pick_device_for_pipeline():\n",
    "#     if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "#         return torch.device(\"mps\")\n",
    "#     elif torch.cuda.is_available():\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return -1\n",
    "\n",
    "# device = pick_device_for_pipeline()\n",
    "\n",
    "# # --- Load data ---\n",
    "# # df = pd.read_csv(CSV_PATH)\n",
    "# df = pd.read_csv(CSV_PATH).head(1000)\n",
    "\n",
    "# texts = df[\"title\"].astype(str).tolist()\n",
    "\n",
    "# # --- Load tokenizer & model (force safetensors to avoid torch.load restriction) ---\n",
    "# def load_model(model_name: str):\n",
    "#     tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "#     mdl = AutoModelForSequenceClassification.from_pretrained(\n",
    "#         model_name,\n",
    "#         use_safetensors=True,   # <- avoids torch.load CVE restriction\n",
    "#     )\n",
    "#     return tok, mdl\n",
    "\n",
    "# try:\n",
    "#     tokenizer, model = load_model(MODEL_NAME)\n",
    "# except Exception as e:\n",
    "#     # Fallback to a multilingual 3-class model with safetensors if needed\n",
    "#     print(f\"[INFO] Could not load '{MODEL_NAME}' with safetensors: {e}\")\n",
    "#     fallback = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "#     print(f\"[INFO] Falling back to '{fallback}' ...\")\n",
    "#     tokenizer, model = load_model(fallback)\n",
    "\n",
    "# # --- Build pipeline ---\n",
    "# nlp = pipeline(\n",
    "#     \"sentiment-analysis\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     framework=\"pt\",\n",
    "#     device=device,\n",
    "# )\n",
    "\n",
    "# # --- Neutral calibration parameters (tune these) ---\n",
    "# NEU_MIN = 0.55    # require at least this much neutral prob to consider neutral\n",
    "# NEU_MARGIN = 0.12 # neutral must exceed max(pos,neg) by this margin\n",
    "\n",
    "# # Helper to convert pipeline output (list of dicts with LABEL_X) to probs dict\n",
    "# def to_prob_dict(items):\n",
    "#     # items like: [{'label':'LABEL_0','score':0.12},{'label':'LABEL_1','score':0.70},{'label':'LABEL_2','score':0.18}]\n",
    "#     mapping = {\"LABEL_0\": \"negative\", \"LABEL_1\": \"neutral\", \"LABEL_2\": \"positive\",\n",
    "#                \"NEGATIVE\": \"negative\", \"NEUTRAL\": \"neutral\", \"POSITIVE\": \"positive\"}\n",
    "#     out = {}\n",
    "#     for d in items:\n",
    "#         out[mapping.get(d[\"label\"].upper(), d[\"label\"].lower())] = float(d[\"score\"])\n",
    "#     # Ensure all keys exist\n",
    "#     for k in (\"positive\", \"neutral\", \"negative\"):\n",
    "#         out.setdefault(k, 0.0)\n",
    "#     return out\n",
    "\n",
    "# def decide_label(p):\n",
    "#     # p is dict: {'positive': p_pos, 'neutral': p_neu, 'negative': p_neg}\n",
    "#     p_pos, p_neu, p_neg = p[\"positive\"], p[\"neutral\"], p[\"negative\"]\n",
    "#     best_non_neu = max(p_pos, p_neg)\n",
    "\n",
    "#     # Only assign neutral if it clears both a minimum AND a margin over pos/neg\n",
    "#     if (p_neu >= NEU_MIN) and ((p_neu - best_non_neu) >= NEU_MARGIN):\n",
    "#         return \"neutral\"\n",
    "#     # Otherwise go with the non-neutral argmax\n",
    "#     return \"positive\" if p_pos >= p_neg else \"negative\"\n",
    "\n",
    "# # --- Inference with text-only progress (and return_all_scores for calibration) ---\n",
    "# batch_size = 128\n",
    "# results = []\n",
    "# for i in tqdm(\n",
    "#     range(0, len(texts), batch_size),\n",
    "#     desc=\"Scoring headlines\",\n",
    "#     ascii=True,\n",
    "#     dynamic_ncols=True,\n",
    "#     leave=True,\n",
    "#     file=sys.stdout,\n",
    "# ):\n",
    "#     batch = texts[i:i+batch_size]\n",
    "#     # Ask pipeline for all class scores to apply our rule\n",
    "#     # Note: return_all_scores=True makes pipeline return a list per input\n",
    "#     scored = nlp(\n",
    "#         batch,\n",
    "#         batch_size=batch_size,\n",
    "#         truncation=True,\n",
    "#         padding=True,\n",
    "#         max_length=48,\n",
    "#         return_all_scores=True,\n",
    "#     )\n",
    "#     # Convert each item's LABEL_X list to probabilities dict and decide label\n",
    "#     for item in scored:\n",
    "#         p = to_prob_dict(item)\n",
    "#         results.append(decide_label(p))\n",
    "\n",
    "# df[\"sentiment\"] = results\n",
    "\n",
    "# # --- Distribution ---\n",
    "# dist = (df[\"sentiment\"].value_counts(normalize=True) * 100).reindex(\n",
    "#     [\"positive\", \"neutral\", \"negative\"]\n",
    "# ).fillna(0).round(2)\n",
    "\n",
    "# print(\"\\nSentiment distribution (%):\")\n",
    "# print(dist.to_string())\n",
    "\n",
    "# # --- Show 5 examples per class ---\n",
    "# for s in [\"positive\", \"neutral\", \"negative\"]:\n",
    "#     print(f\"\\n{s.upper()} EXAMPLES:\")\n",
    "#     ex = df.loc[df[\"sentiment\"] == s, \"title\"].head(5)\n",
    "#     if ex.empty:\n",
    "#         print(\" (none found)\")\n",
    "#     else:\n",
    "#         for t in ex:\n",
    "#             print(\" -\", t)\n",
    "\n",
    "# # --- Save ---\n",
    "# out_path = \"sp500_headlines_with_calibrated_sentiment.csv\"\n",
    "# df.to_csv(out_path, index=False)\n",
    "# print(f\"\\nSaved results to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2c999-5dd6-4733-af8f-da8893838e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
